---
title: "machine learning"
author: "Julian Zamudio"
date: "12/22/2020"
output: html_document
---
## Summary 

# Colecting the data

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(ggplot2)
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")

```

## Preliminary data analysis

# cleaning Data

All the incomplete data as NA values and  non- defined values were excluded from the training data set. The variables to be used are the variables with values in the testing data set, therefore the columns with NA values are removed from the testing and training data set.

```{r}
library(caret)
set.seed(34567)
# removing the columns with NA's in the quiz test
testing.1 <-testing[,colSums(!is.na(testing)) > 0]
testing.1 <- testing.1[,-c(1:7)]
name.1 <- c(names(testing.1), "classe")

# cleaning the training set

training[training == ""] <- NA

# creating the training set with NA's columns

name.2 <- names(training)
training.1 <- training[,which(name.2 %in% name.1)]
name.3 <- names(training.1)
miss.1 <- name.1[-which(name.1 %in% name.3)]
testing.1 <- testing.1[,-which(name.1 %in% miss.1)]

# Creating the training and test set

inTrain  <- createDataPartition(training.1$classe, p=0.7, list=FALSE)
Train <- training.1[inTrain, ]
Test  <- training.1[-inTrain, ]

```

The data clean  reduce the NA to less than 5 %. Additionally most of the data was keep it. To define with columns to keep the quiz data set was used. The  Columns with NA values was removed from it. Then, the same columns were removed from the data set. Afterwards,  the Train and Test set were created in  from the training data set. 

## Defining the model


# testing random model fit 


```{r cache=TRUE}
# creating the model 

modcontrol <- trainControl(method= "cv")
modrandom <- train(classe ~ ., data=Train, method="rf",
                 trControl= modcontrol, prox = TRUE)

# getting the results from the model

print(modrandom)
modrandom$finalModel

```

The accuracy of the method  for  is above 0.99. The kappa coefficients as well. The error per classe is in general below 0.02 and the overall estimated error is 0.72%.   

# Testing the Random forest model


```{r}

predrandom <- predict( modrandom,newdata = Test)
confusionMatrix(predrandom,Test$classe)
```

# Discussion

No forecast was done in the data sets. it is defined not relevant in this study. The results are not shown, but unsupervised method and linear regression have low accuracy. Indeed, those models were discarded. Then the focus was in models to predict  factor outcome. The boosting model( also results are not shown) was tested first because it was found high variance in 0.55 of the predictors in the training data base. It was expected to have compensation for the predictors with large variance using that model.The results seems to have acceptable accuracy at 150 number of trees with 0.70. 

The  random forest method shows high specificity and sensitivity.

# Predicting the testing data set

```{r}
testquiz <- predict(modrandom,testing.1)
qplot(x = c(1:20), y = testquiz, geom = "point", color = testquiz, main = "Predicted classe for the training set", xlab = "Number", ylab = "classe")
```










